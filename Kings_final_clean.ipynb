{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4613e99e",
   "metadata": {},
   "source": [
    "## The Sacramento Kings Playoff Drought\n",
    "### By: Jonathan Donato, Matthew Morisawa, Tony Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0cd3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries necessary for project\n",
    "\n",
    "import requests as rq\n",
    "import lxml.html as lx\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sn\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import statsmodels.api as sm \n",
    "pd.set_option('display.max_columns', None)\n",
    "import plotnine as p9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c007f8",
   "metadata": {},
   "source": [
    "## Obtain Kings Players Stats + Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d72969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read html + make df for general stats\n",
    "url = 'https://www.espn.com/nba/team/stats/_/name/sac/salary'\n",
    "names = pd.read_html(url)[0]\n",
    "stats = pd.read_html(url)[1]\n",
    "kings_stats_temp = pd.concat([names,stats],axis = \"columns\")\n",
    "kings_stats_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_positions(df):\n",
    "    '''Removes The position indicator after each player's name (i.e. PG, PF, SG), also drops the \"Total\" row as it's not needed.'''\n",
    "    words = []\n",
    "    for i in df[\"Name\"]:\n",
    "        words.append(i.split()[0:2])\n",
    "    words = pd.DataFrame(words)\n",
    "    words.columns = [\"First\",\"Last\"]\n",
    "    words[\"Names\"] = words['First']+\" \"+ words[\"Last\"]\n",
    "    words = words.drop(\"First\", axis = 1).drop(\"Last\", axis = 1)\n",
    "    df[\"Name\"] = words\n",
    "    #df = df.drop(16)\n",
    "    df = df.dropna().reset_index().drop(\"index\", axis = \"columns\")\n",
    "    return df\n",
    "\n",
    "kings_stats = remove_positions(kings_stats_temp)\n",
    "kings_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd1eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read html + make df for shooting stats\n",
    "shoot = pd.read_html(url)[3]\n",
    "kings_shoot_stats_temp = pd.concat([names,shoot], axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14639ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "kings_shoot_stats = remove_positions(kings_shoot_stats_temp)\n",
    "kings_shoot_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create salary df\n",
    "url2 = \"https://www.espn.com/nba/team/roster/_/name/sac/salary\"\n",
    "kings_salary_raw = pd.read_html(url2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strips player number from each players name\n",
    "for i in range(0,len(kings_salary_raw)):\n",
    "    kings_salary_raw[\"Name\"][i] = re.sub(r\"\\d+\", \"\", str(kings_salary_raw[\"Name\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleans dataframe to only player name + salary\n",
    "kings_salary = kings_salary_raw.set_index(\"Name\").drop('Unnamed: 0', axis = 1)\n",
    "kings_salary.columns\n",
    "kings_salary = kings_salary.drop(['POS', 'Age', 'HT', 'WT', 'College'], axis = 1)\n",
    "kings_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40259c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine player stats df and salary df as kings_stats_salary. \n",
    "pd.set_option('display.max_columns', None)\n",
    "kings_stats_salary = kings_stats.join(kings_salary, on = \"Name\")\n",
    "kings_stats_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f4825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine kings shooting stats df with \"kings_stats_salary\".\n",
    "kings_player_shooting_salary = pd.merge(kings_stats_salary,kings_shoot_stats, how = \"left\", on = \"Name\")\n",
    "kings_player_shooting_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514082bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearrange salary to column to go at the end.\n",
    "salary = kings_player_shooting_salary.pop(\"Salary\")\n",
    "kings_final_df = pd.concat([kings_player_shooting_salary, salary], axis = 'columns')\n",
    "kings_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aquring links in raw form\n",
    "url = \"https://www.espn.com/nba/teams\"\n",
    "result = requests.get(url)\n",
    "soup = BeautifulSoup(result.text, 'html.parser')\n",
    "links = [str(link.get('href')) for link in soup.find_all(\"a\")]\n",
    "links_df = pd.DataFrame(links)\n",
    "links_df.columns = [\"links\"]\n",
    "pattern = re.compile(r'/nba/team/stats/_/name/+')\n",
    "stats_links_df = links_df[links_df['links'].str.contains(pattern, regex = True)]\n",
    "print(links_df)\n",
    "stats_links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_links_df = stats_links_df.reset_index().drop(\"index\", axis = \"columns\")\n",
    "west_conference = pd.concat([stats_links_df.iloc[10:20,:],stats_links_df.iloc[25:,:]])\n",
    "west_conference_stats_links = west_conference.reset_index().drop(\"index\", axis = \"columns\")\n",
    "#links to team stats that are only in the western conference\n",
    "west_conference_stats_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f90da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing kings from links\n",
    "west_conference_stats_links = west_conference_stats_links.drop(9, axis = \"rows\").reset_index().drop(\"index\",axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1aa9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire raw data\n",
    "players_df = pd.DataFrame()\n",
    "for link in west_conference_stats_links[\"links\"]:\n",
    "    url = \"https://www.espn.com\"+link\n",
    "    player_names = pd.read_html(url)[0]\n",
    "    player_stats = pd.read_html(url)[1]\n",
    "    player_concat = pd.concat([player_names,player_stats],axis = \"columns\")\n",
    "    players_df = pd.concat([players_df, player_concat], ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "remove_positions(players_df)\n",
    "#Cleaned up dataframe with all player stats in western conference\n",
    "pd.set_option('display.max_rows', None)\n",
    "players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df_shoot = pd.DataFrame()\n",
    "for link in west_conference_stats_links[\"links\"]:\n",
    "    url = \"https://www.espn.com\"+link\n",
    "    player_names = pd.read_html(url)[0]\n",
    "    player_shoot = pd.read_html(url)[3]\n",
    "    player_concat = pd.concat([player_names,player_shoot],axis = \"columns\")\n",
    "    \n",
    "    players_df_shoot = pd.concat([players_df_shoot, player_concat], ignore_index = True)\n",
    "\n",
    "remove_positions(players_df_shoot)\n",
    "#Cleaned up dataframe with all player stats in western conference\n",
    "players_df_shoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769204aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next few cells are for acquiring salary of all players in western conference\n",
    "\n",
    "url2 = \"https://www.espn.com/nba/team/roster/_/name/sac/salary\"\n",
    "kings_salary_raw = pd.read_html(url2)[0]\n",
    "\n",
    "pattern_sal = re.compile(r'/nba/team/roster/_/+')\n",
    "sal_links_df = links_df[links_df['links'].str.contains(pattern_sal, regex = True)]\n",
    "\n",
    "\n",
    "west_conference_sal = pd.concat([sal_links_df.iloc[10:20,:],sal_links_df.iloc[25:,:]])\n",
    "west_conference_sal_links = west_conference_sal.reset_index().drop(\"index\", axis = \"columns\")\n",
    "#links to all pages with team salaries\n",
    "west_conference_sal_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed kings from links\n",
    "west_conference_sal_links = west_conference_sal_links.drop(9, axis = \"rows\").reset_index().drop(\"index\",axis = \"columns\")\n",
    "west_conference_sal_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What the salary page returns; we only care about name and salary\n",
    "pd.read_html(\"https://www.espn.com/nba/team/roster/_/name/den/denver-nuggets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e500874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquiring the salaries from the links\n",
    "sal_players_df = pd.DataFrame()\n",
    "for link in west_conference_sal_links[\"links\"]:\n",
    "    url = \"https://www.espn.com\"+link\n",
    "    player_salaries = pd.read_html(url)[0]\n",
    "    sal_players_df = pd.concat([sal_players_df, player_salaries], ignore_index = True)\n",
    "sal_players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d724ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning\n",
    "for i in range(0,len(sal_players_df)):\n",
    "    sal_players_df.loc[:,\"Name\"][i] = re.sub(r\"\\d+\", \"\", str(sal_players_df.loc[:,\"Name\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54c4342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning\n",
    "sal_players_df = sal_players_df.set_index(\"Name\").drop('Unnamed: 0', axis = 1)\n",
    "sal_players_df = sal_players_df.drop(['POS', 'Age', 'HT', 'WT', 'College'], axis = 1)\n",
    "#Clean salary dataframe\n",
    "sal_players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cf8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge western conference player stats with their salaries\n",
    "players_stats_salary = pd.merge(players_df,sal_players_df, how = \"left\", on = \"Name\")\n",
    "player_stats_shoot_salary = pd.merge(players_stats_salary, players_df_shoot, how = \"left\", on = \"Name\")\n",
    "player_stats_shoot_salary\n",
    "salary = player_stats_shoot_salary.pop(\"Salary\")\n",
    "player_stats_shoot_salary = pd.concat([player_stats_shoot_salary, salary], axis = 'columns')\n",
    "player_stats_shoot_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e6f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all the \"--\" and NAN to 0\n",
    "player_stats_shoot_salary['Salary'] = player_stats_shoot_salary['Salary'].replace(\"--\", '0')\n",
    "player_stats_shoot_salary['Salary'] = player_stats_shoot_salary['Salary'].replace(np.NaN, '0')\n",
    "#remove $ and , signals\n",
    "for i in range(0,len(player_stats_shoot_salary)):\n",
    "    player_stats_shoot_salary['Salary'][i] = player_stats_shoot_salary['Salary'][i].lstrip('$')\n",
    "    player_stats_shoot_salary['Salary'][i] = player_stats_shoot_salary['Salary'][i].replace(',','')\n",
    "    #turn Salary to numbers\n",
    "    player_stats_shoot_salary['Salary'][i] = int(player_stats_shoot_salary['Salary'][i])\n",
    "#replace all 0 to NAN\n",
    "player_stats_shoot_salary['Salary'] = player_stats_shoot_salary['Salary'].replace(0, np.NaN)\n",
    "#drop all NAN\n",
    "player_stats_shoot_salary_temp = player_stats_shoot_salary.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final dataset\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "player_stats_shoot_salary_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c656014e",
   "metadata": {},
   "source": [
    "## Obtain NBA Team Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67285418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain basic nba stats for past 5 seasons\n",
    "nbateamstats = pd.DataFrame()\n",
    "for i in range(2023,2018, -1):\n",
    "    tempurl = \"https://www.espn.com/nba/stats/team/_/view/opponent/season/\"+str(i)+\"/seasontype/2\"\n",
    "    team_names = pd.read_html(tempurl)[0]\n",
    "    team_stats = pd.read_html(tempurl)[1]\n",
    "    team_stats\n",
    "    team_concat = pd.concat([team_names,team_stats],axis = \"columns\")\n",
    "    team_concat['Team'] = str(i) + \" \" + team_concat['Team'].astype(str)\n",
    "    nbateamstats = pd.concat([nbateamstats, team_concat], ignore_index = True)\n",
    "nbateamstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e41774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable to store all nba team names to help standardize nba team names between data frames\n",
    "nbateams = pd.read_html(\"https://www.espn.com/nba/stats/team/_/view/opponent/season/2023/seasontype/2\")[0][\"Team\"]\n",
    "nbateams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6894ee84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_teams(team, stats):\n",
    "    #Function fixes errors caused by read_html function. Makes the \"row header\" back into the first row\n",
    "    team1 = team.columns[0] \n",
    "    team.columns = [\"Team\"]\n",
    "    new_row = pd.DataFrame({team.columns[0]:team1}, index=[0])\n",
    "    team = pd.concat([new_row,team.loc[:]]).reset_index(drop=True)\n",
    "    #Standardizes NBA team names across dataframes to allow easy joining between them\n",
    "    for i in range(0, len(team.iloc[:,0])):\n",
    "        for teamname in nbateams:\n",
    "            if team.iloc[:,0][i].__contains__(teamname):\n",
    "                team.iloc[:,0][i] = teamname\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    result = team.join(stats.iloc[:,0:2])\n",
    "    return(result)\n",
    "    \n",
    "def add_playoff_status(df, year):\n",
    "    #df input: conference standings (15 teams) ranked in order by wins\n",
    "    #creates new variable that shows if a certain team made the playoffs \n",
    "    #2023 is the current season and the playoffs have not happened yet, therefore NaN\n",
    "    if year == 2023:\n",
    "        df[\"Made Playoffs\"] = math.nan\n",
    "        return(df)\n",
    "    df[\"Made Playoffs\"] = int(0)\n",
    "    #2019-20 top 8 teams per conference made playoffs\n",
    "    if year in [2019, 2020]:\n",
    "        for index in df.index:\n",
    "            if index < 8:\n",
    "                df.iloc[index,3] = int(1)\n",
    "    #2021-22 top 10 teams per conference made playoffs\n",
    "    else:\n",
    "        for index in df.index:\n",
    "            if index < 10:\n",
    "                df.iloc[index,3] = int(1)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "#create a df to capture wins/losses for each team in past 5 seasons\n",
    "league_wins_losses = pd.DataFrame()\n",
    "for i in range(2023,2018, -1):\n",
    "    urlstandings = \"https://www.espn.com/nba/standings/_/season/\"+ str(i)\n",
    "    teams_east = pd.read_html(urlstandings)[0]\n",
    "    stats_east = pd.read_html(urlstandings)[1]\n",
    "    teams_west = pd.read_html(urlstandings)[2]\n",
    "    stats_west = pd.read_html(urlstandings)[3]\n",
    "    teams_east = clean_teams(teams_east, stats_east)\n",
    "    teams_east = add_playoff_status(teams_east, i)\n",
    "    teams_west = clean_teams(teams_west, stats_west)\n",
    "    teams_west = add_playoff_status(teams_west, i)\n",
    "    df_win_loss = pd.concat([teams_east, teams_west], ignore_index = True)\n",
    "    df_win_loss['Team'] = str(i) + \" \" + df_win_loss['Team'].astype(str)\n",
    "    league_wins_losses = pd.concat([league_wins_losses, df_win_loss], ignore_index = True)\n",
    "league_wins_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a720cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dfs and drop \"rank\" variable (not needed)\n",
    "fullnbastats = pd.merge(league_wins_losses, nbateamstats, on=\"Team\")\n",
    "fullnbastats = fullnbastats.drop(['RK'], axis=1)\n",
    "fullnbastats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b74b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df that captures efficiency stats (pace, off eff, def eff, etc)\n",
    "\n",
    "nbaefficiencystats = pd.DataFrame()\n",
    "for year in range(2023,2018, -1):\n",
    "    efficiencyurl = \"http://www.espn.com/nba/hollinger/teamstats/_/sort/defensiveEff/year/\"+ str(year)\n",
    "    efficiencystats = pd.read_html(efficiencyurl)[0].iloc[1: , 1:]\n",
    "    efficiencystats = pd.DataFrame(efficiencystats.values[1:], columns=efficiencystats.iloc[0])\n",
    "    for i in range(0, len(efficiencystats.iloc[:,0])):\n",
    "        for teamname in nbateams:\n",
    "            if efficiencystats.iloc[:,0][i] == \"LA Lakers\":\n",
    "                efficiencystats.iloc[:,0][i] = \"Los Angeles Lakers\"\n",
    "                break\n",
    "            if efficiencystats.iloc[:,0][i] in teamname:\n",
    "                efficiencystats.iloc[:,0][i] = teamname\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    efficiencystats = efficiencystats.rename(columns = {\"TEAM\": \"Team\"})\n",
    "    efficiencystats['Team'] = str(year) + \" \" + efficiencystats['Team'].astype(str)\n",
    "    efficiencystats = efficiencystats[[\"Team\", \"PACE\", \"EFF FG%\", \"OFF EFF\", \"DEF EFF\"]]\n",
    "    nbaefficiencystats = pd.concat([nbaefficiencystats, efficiencystats], ignore_index = True)\n",
    "nbaefficiencystats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acabed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine efficiency df to rest of stats df\n",
    "fullnbastats = pd.merge(fullnbastats, nbaefficiencystats, on=\"Team\")\n",
    "fullnbastats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef26558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put \"made playoffs\" as last variable as it is our response variable\n",
    "playoffstat = fullnbastats.pop(\"Made Playoffs\")\n",
    "fullnbastats[\"Made Playoffs\"] = playoffstat\n",
    "fullnbastats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change variables to floats (originally were objects)\n",
    "fullnbastats[\"PACE\"] = fullnbastats[\"PACE\"].astype(float)\n",
    "fullnbastats[\"EFF FG%\"] = fullnbastats[\"EFF FG%\"].astype(float)\n",
    "fullnbastats[\"OFF EFF\"] = fullnbastats[\"OFF EFF\"].astype(float)\n",
    "fullnbastats[\"DEF EFF\"] = fullnbastats[\"DEF EFF\"].astype(float)\n",
    "#get df of just Kings over past 5 years\n",
    "kingsfullstats_5years = fullnbastats[fullnbastats['Team'].str.contains('Kings')]\n",
    "#get index of current Kings season to be used in future\n",
    "kingsindex = fullnbastats[fullnbastats['Team'] == '2023 Sacramento Kings'].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04acb9c",
   "metadata": {},
   "source": [
    "## Plotting NBA Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0194ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function that will create visualizations. plots teams by playoff status. also emphasizes Kings points as well as point to current Kings stats\n",
    "def comparison_plot(df, index1, index2, xloc, yloc):\n",
    "    groups = df.groupby(\"Made Playoffs\")\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for name, group in groups:\n",
    "        if name == 0:\n",
    "            name = \"Did Not Make Playoffs\"\n",
    "            playoffcolor = 'crimson'\n",
    "        else:\n",
    "            name = \"Made Playoffs\"\n",
    "            playoffcolor = 'royalblue'\n",
    "        plt.plot(group.iloc[:,index1], group.iloc[:,index2], marker=\".\", linestyle=\"\", label=name, color = playoffcolor)\n",
    "    plt.legend()\n",
    "    plt.plot(kingsfullstats_5years.iloc[:,index1], kingsfullstats_5years.iloc[:,index2], linestyle='none', marker = 'o', color ='darkorchid')\n",
    "    plt.annotate('Sacramento Kings 2022-23', \n",
    "             xy=(df.iloc[kingsindex,index1], df.iloc[kingsindex,index2]), \n",
    "             xytext=(df.iloc[kingsindex,index1] + xloc, df.iloc[kingsindex,index2] + yloc),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "    plt.axvline(mean(fullnbastats.iloc[:,index1]), color='k', linestyle='dashed')\n",
    "    plt.axhline(mean(fullnbastats.iloc[:,index2]), color='k', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c535b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create comparison for offensive and defensive efficiency\n",
    "comparison_plot(fullnbastats, fullnbastats.columns.get_loc(\"OFF EFF\"), fullnbastats.columns.get_loc(\"DEF EFF\"), -0.5, 1.5)\n",
    "plt.xlabel(\"Offensive Efficiency (Pts Scored/100 Poss)\")\n",
    "plt.ylabel(\"Defensive Efficiency (Pts Allowed/100 Poss)\")\n",
    "plt.title(\"Offensive vs Defensive Efficiency in NBA 2018-2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create comparison for assists and turnovers\n",
    "comparison_plot(fullnbastats, fullnbastats.columns.get_loc(\"AST\"), fullnbastats.columns.get_loc(\"TO\"), -2, 1.5)\n",
    "plt.xlabel(\"Assists Per Game\")\n",
    "plt.ylabel(\"Turnovers Per Game\")\n",
    "plt.title(\"Assists vs Turnovers in NBA 2018-2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create comparison for offensive and defensive rebounds\n",
    "comparison_plot(fullnbastats, fullnbastats.columns.get_loc(\"OR\"), fullnbastats.columns.get_loc(\"DR\"), 0, -0.75)\n",
    "plt.xlabel(\"Offensive Rebounds Per Game\")\n",
    "plt.ylabel(\"Defensive Rebounds Per Game\")\n",
    "plt.title(\"Offensive vs Defensive Rebounds in NBA 2018-2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create comparison for effective field goal % and pace\n",
    "comparison_plot(fullnbastats, fullnbastats.columns.get_loc(\"EFF FG%\"), fullnbastats.columns.get_loc(\"PACE\"), -2.25, 1)\n",
    "plt.xlabel(\"Effective Field Goal Percentage Per Game\")\n",
    "plt.ylabel(\"Pace Per Game\")\n",
    "plt.title(\"Effective Field Goal Percentage vs Pace in NBA 2018-2023\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607a06d",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cd139a",
   "metadata": {},
   "source": [
    "### DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6b033",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Non-kings player data\n",
    "df = player_stats_shoot_salary_temp\n",
    "df_names = df[\"Name\"]\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d0bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kings data\n",
    "kings_df = kings_final_df\n",
    "kings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278dda45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_clean(df):\n",
    "    #Dropping name to enable linear regression\n",
    "    df = df.drop(\"Name\", axis = \"columns\").dropna()\n",
    "    # AST/TO has some infinities, dropping them\n",
    "    drop_df = df[df[\"AST/TO\"].isin([np.inf, -np.inf])]\n",
    "    df = df.drop(drop_df.index)\n",
    "    for name in df.columns:\n",
    "        # Dropping, as these variables are made redundant by their corresponding percentages: (FG%, 2P%, ...)\n",
    "        if name in [\"FGM\",\"FGA\",\"3PM\",\"3PA\",\"2PM\",\"2PA\",\"FTM\",\"FTA\"]:\n",
    "            df = df.drop(name, axis = \"columns\") \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec0edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning df\n",
    "df = df_clean(df)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f8b1b6",
   "metadata": {},
   "source": [
    "### MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9868e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sm.add_constant(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build ols model\n",
    "ols = sm.OLS(np.log(df['Salary']),df.drop(columns = 'Salary')) \n",
    "ols_res = ols.fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d27a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e3f0b",
   "metadata": {},
   "source": [
    "##### The drops below were intentionally done one at a time, as a part of model selection. We checked how dropping each variable affected the other p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8da50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"OR\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54580267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"STL\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339fd70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"PF\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"TO\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"BLK\", axis = \"columns\") #.473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad615c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"FG%\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c38d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"AST/TO\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dffee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"SH-EFF\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"GS\", axis = \"columns\") #.482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5528ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"REB\", axis = \"columns\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"3P%\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a5743e",
   "metadata": {},
   "source": [
    "### MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d89c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up and running linear regression\n",
    "#Log transform salary due to salary's right skew\n",
    "ols = sm.OLS(np.log(df['Salary']),df.drop(columns = 'Salary')) \n",
    "ols_res = ols.fit() \n",
    "ols_res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655c4d2",
   "metadata": {},
   "source": [
    "### DIAGNOSTIC PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted vs residual plot\n",
    "\n",
    "(\n",
    "    p9.ggplot(mapping = p9.aes(x = 'ols_res.fittedvalues', \n",
    "                                            y = \"ols_res.resid_pearson\"))\n",
    "    + p9.geom_point()\n",
    "    + p9.geom_smooth(color = \"red\")\n",
    "    + p9.labs(title = \"Fitted vs Residuals\", x = 'Fitted values', y = 'Residuals')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qq-plot\n",
    "\n",
    "(\n",
    "    p9.ggplot(mapping = p9.aes(sample = \"ols_res.resid_pearson\"))\n",
    "    + p9.geom_abline(p9.aes(intercept = 0, slope = 1), color = 'red')\n",
    "    + p9.stats.stat_qq()\n",
    "    + p9.labs(title = \"QQ-Plot with Pearson Residuals\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279855e3",
   "metadata": {},
   "source": [
    "### REMOVE OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a583bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Residuals\"] = ols_res.resid_pearson\n",
    "temp_df2 = df[round(df[\"Residuals\"]) < -2]\n",
    "#row with residual outliers\n",
    "temp_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08760172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outlier rows\n",
    "df = df.drop(temp_df2.index)\n",
    "df = df.drop(\"Residuals\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rerun model without outliers\n",
    "ols = sm.OLS(np.log(df['Salary']),df.drop(columns = 'Salary')) \n",
    "ols_res = ols.fit() \n",
    "ols_res.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted vs residuals\n",
    "\n",
    "(\n",
    "    p9.ggplot(mapping = p9.aes(x = 'ols_res.fittedvalues', \n",
    "                                            y = \"ols_res.resid_pearson\"))\n",
    "    + p9.geom_point()\n",
    "    + p9.geom_smooth(color = \"red\")\n",
    "    + p9.labs(title = \"Fitted vs Residuals\", x = 'Fitted values', y = 'Residuals')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8dbdc",
   "metadata": {},
   "source": [
    "##### Homoscedascity assumption satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cc51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##qq plot\n",
    "\n",
    "(\n",
    "    p9.ggplot(mapping = p9.aes(sample = \"ols_res.resid_pearson\"))\n",
    "    + p9.geom_abline(p9.aes(intercept = 0, slope = 1), color = 'red')\n",
    "    + p9.stats.stat_qq()\n",
    "    + p9.labs(title = \"QQ-Plot with Pearson Residuals\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a723832",
   "metadata": {},
   "source": [
    "##### Normality of error variances assumption satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450ea1e",
   "metadata": {},
   "source": [
    "### Running the Model on the Kings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4935c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "kings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2890b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all the \"--\" and NAN to 0\n",
    "\n",
    "kings_df['Salary'] = kings_df['Salary'].replace(\"--\", '0')\n",
    "kings_df['Salary'] = kings_df['Salary'].replace(np.NaN, '0')\n",
    "#remove $ and , signals\n",
    "for i in range(0,len(kings_df)):\n",
    "    kings_df['Salary'][i] = kings_df['Salary'][i].lstrip('$')\n",
    "    kings_df['Salary'][i] = kings_df['Salary'][i].replace(',','')\n",
    "    #turn Salary to numbers\n",
    "    kings_df['Salary'][i] = int(kings_df['Salary'][i])\n",
    "#replace all 0 to NAN\n",
    "kings_df['Salary'] = kings_df['Salary'].replace(0, np.NaN)\n",
    "#drop all NAN\n",
    "kings_df = kings_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kings_names = kings_df[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df9fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kings_df = df_clean(kings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d96768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropped same variables as from non-kings dataframe\n",
    "kings_df = kings_df.drop(\"OR\", axis = \"columns\")\n",
    "kings_df = kings_df.drop(\"STL\", axis = \"columns\")\n",
    "kings_df = kings_df.drop(\"PF\", axis = \"columns\")\n",
    "kings_df = kings_df.drop(\"TO\", axis = \"columns\")\n",
    "kings_df = kings_df.drop(\"BLK\", axis = \"columns\")\n",
    "kings_df = kings_df.drop(\"FG%\", axis = \"columns\")\n",
    "kings_df = kings_df.drop(\"AST/TO\", axis = \"columns\")\n",
    "kings_df = kings_df.drop(\"SH-EFF\", axis = \"columns\")\n",
    "kings_df = kings_df.drop(\"GS\", axis = \"columns\")\n",
    "kings_df = kings_df.drop(\"REB\", axis = \"columns\") \n",
    "kings_df = kings_df.drop(\"3P%\", axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kings_df = sm.add_constant(kings_df)\n",
    "kings_df[\"GP\"] = kings_df[\"GP\"].astype(\"float64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8740ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted salary values\n",
    "ols_res.predict(kings_df.drop(columns = 'Salary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating predicted and residuals columns\n",
    "kings_df[\"Predicted\"] = np.exp(ols_res.predict(kings_df.drop(columns = 'Salary')))\n",
    "kings_df.insert(0,\"Names\",kings_names)\n",
    "kings_df[\"Residuals\"]= kings_df[\"Salary\"]-kings_df[\"Predicted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb362098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "kings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bbce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Team overall is overvalued\n",
    "kings_df[\"Residuals\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff93876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dataframe with log values instead\n",
    "kings_df[\"Salary\"] = np.log(kings_df[\"Salary\"])\n",
    "kings_df[\"Predicted\"] =  np.log(kings_df[\"Predicted\"])\n",
    "kings_df[\"Residuals\"]= kings_df[\"Salary\"]-kings_df[\"Predicted\"]\n",
    "kings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log version\n",
    "kings_df[\"Residuals\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f907cfe7",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1235a",
   "metadata": {},
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f42c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop first 30 rows (current season which we do not want)\n",
    "#drop \"made playoffs\" (response), \"team\" (unique identifier), and \"GP\" (GP = W + L, so causing issue being a linear combination)\n",
    "x = fullnbastats[30:].drop(columns = ['Made Playoffs', 'Team', 'GP'])\n",
    "y= fullnbastats[\"Made Playoffs\"][30:]\n",
    "#compute vifs for each variable to determine which can be used\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
    "vif[\"features\"] = x.columns\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3dc9ea",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed60474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data by centering each variable by respective mean\n",
    "standardizeddata = fullnbastats.drop(columns = ['Made Playoffs', 'Team'])\n",
    "colnames = standardizeddata.columns\n",
    "standardizeddata = pd.DataFrame(preprocessing.scale(standardizeddata))\n",
    "standardizeddata.columns = colnames\n",
    "standardizeddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cdf5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut df to not include current season. run vif and drop variables one by one until all vifs are <10\n",
    "x = standardizeddata[30:]\n",
    "x = x.drop(columns = ['GP', 'FGM', 'FGA', 'FTM', 'FTA', '3PM', '3PA', 'REB', 'PACE', 'OFF EFF', 'DEF EFF'])\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
    "vif[\"features\"] = x.columns\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb667d0b",
   "metadata": {},
   "source": [
    "### Building The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9d1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train/test data using 80:20 ratio\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff2fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build our model using train/test data. see what the accuracy is\n",
    "model = LogisticRegression(solver='liblinear', C = 10, random_state=0, max_iter = 1000)\n",
    "model.fit(x_train, y_train)\n",
    "model.classes_\n",
    "model.intercept_\n",
    "model.coef_\n",
    "model.predict_proba(x_test)\n",
    "model.predict(x_test)\n",
    "print(\"Model Accuracy:\", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a confusion matrix to see how our model is performing\n",
    "cm = confusion_matrix(y_test, model.predict(x_test))\n",
    "df_cm = pd.DataFrame(cm, ['No Playoffs', 'Playoffs'], ['Predicted No Playoffs', 'Predicted Playoffs'])\n",
    "plt.figure(figsize=(8,8))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775ae4e",
   "metadata": {},
   "source": [
    "### Running Model on Kings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549be213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run our model specifically on Kings 22-23 data to see if they make playoffs or not\n",
    "kingsfullnbastats23 = standardizeddata.iloc[kingsindex,:].drop(columns = ['GP', 'FGM', 'FGA', 'FTM', 'FTA', '3PM', '3PA', 'REB', 'PACE', 'OFF EFF', 'DEF EFF'])\n",
    "print(\"Kings Probability of Not Making Playoffs:\", model.predict_proba(kingsfullnbastats23)[0][0])\n",
    "print(\"Kings Probability of Making Playoffs:\", model.predict_proba(kingsfullnbastats23)[0][1])\n",
    "print(\"Will Kings Make Playoffs?: (0 if no, 1 if yes)\", model.predict(kingsfullnbastats23)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
